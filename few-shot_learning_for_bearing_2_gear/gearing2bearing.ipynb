{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "# set the memory usage\n",
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=tf_config))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import imp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets/CWRU 12DriveEndFault 1772\n",
      "0 Datasets/CWRU/NormalBaseline/1772/Normal.mat\n",
      "(483903, 2)\n",
      "1 Datasets/CWRU/12DriveEndFault/1772/0.007-Ball.mat\n",
      "(121410, 2)\n",
      "2 Datasets/CWRU/12DriveEndFault/1772/0.014-Ball.mat\n",
      "(122136, 2)\n",
      "3 Datasets/CWRU/12DriveEndFault/1772/0.021-Ball.mat\n",
      "(121701, 2)\n",
      "4 Datasets/CWRU/12DriveEndFault/1772/0.007-InnerRace.mat\n",
      "(121991, 2)\n",
      "5 Datasets/CWRU/12DriveEndFault/1772/0.014-InnerRace.mat\n",
      "(121846, 2)\n",
      "6 Datasets/CWRU/12DriveEndFault/1772/0.021-InnerRace.mat\n",
      "(121556, 2)\n",
      "7 Datasets/CWRU/12DriveEndFault/1772/0.007-OuterRace6.mat\n",
      "(122426, 2)\n",
      "8 Datasets/CWRU/12DriveEndFault/1772/0.014-OuterRace6.mat\n",
      "(122136, 2)\n",
      "9 Datasets/CWRU/12DriveEndFault/1772/0.021-OuterRace6.mat\n",
      "(121991, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " [('NormalBaselineNormal', 0),\n",
       "  ('12DriveEndFault0.007-Ball', 1),\n",
       "  ('12DriveEndFault0.014-Ball', 2),\n",
       "  ('12DriveEndFault0.021-Ball', 3),\n",
       "  ('12DriveEndFault0.007-InnerRace', 4),\n",
       "  ('12DriveEndFault0.014-InnerRace', 5),\n",
       "  ('12DriveEndFault0.021-InnerRace', 6),\n",
       "  ('12DriveEndFault0.007-OuterRace6', 7),\n",
       "  ('12DriveEndFault0.014-OuterRace6', 8),\n",
       "  ('12DriveEndFault0.021-OuterRace6', 9)],\n",
       " 6600,\n",
       " 250)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cwru \n",
    "\n",
    "window_size = 2048\n",
    "data = cwru.CWRU(['12DriveEndFault'], ['1772'], window_size)\n",
    "data.nclasses,data.classes,len(data.X_train),len(data.X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chip5a_x.npy\n",
      "./Datasets/gearing/chip5a_x.npy\n",
      "health_x.npy\n",
      "./Datasets/gearing/health_x.npy\n",
      "spall_x.npy\n",
      "./Datasets/gearing/spall_x.npy\n",
      "missing_x.npy\n",
      "./Datasets/gearing/missing_x.npy\n",
      "crack_x.npy\n",
      "./Datasets/gearing/crack_x.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from  preprocess import prepro\n",
    "path = r'./Datasets/gearing'\n",
    "train_X, train_Y, valid_X, valid_Y, test_X, test_Y = prepro(d_path=path,\n",
    "                                                                length=2048,\n",
    "                                                                number=4000,\n",
    "                                                                normal=False,\n",
    "                                                                rate=[0.1, 0.45, 0.45],\n",
    "                                                                enc=False,\n",
    "                                                                enc_step=28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9002, 2048)\n",
      "[[0 1 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " ...\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]]\n",
      "[1, 0, 1, 2, 3, 3, 4, 4, 4, 3, 3, 0, 2, 3, 0, 4, 2, 1, 1, 1, 1, 1, 2, 0, 0, 2, 0, 3, 4, 1, 2, 2, 3, 3, 0, 2, 4, 3, 1, 2, 1, 4, 3, 1, 0, 4, 3, 2, 4, 3, 2, 2, 0, 4, 1, 4, 3, 1, 4, 0, 3, 2, 0, 4, 4, 4, 4, 1, 0, 1, 4, 2, 3, 0, 0, 0, 1, 0, 3, 4, 3, 2, 1, 0, 2, 3, 3, 2, 1, 3, 3, 0, 3, 0, 2, 1, 2, 1, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n",
      "(9003, 2048)\n",
      "[[1 0 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 1 0 0]\n",
      " ...\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]]\n",
      "[0, 4, 2, 0, 1, 2, 4, 2, 2, 3, 3, 4, 1, 4, 3, 1, 1, 1, 3, 1, 4, 1, 0, 1, 0, 1, 4, 4, 4, 0, 4, 0, 2, 0, 1, 3, 3, 4, 4, 2, 2, 1, 2, 1, 3, 3, 4, 3, 4, 2, 3, 2, 1, 1, 4, 4, 4, 0, 1, 1, 0, 3, 2, 4, 4, 2, 0, 0, 2, 2, 1, 0, 2, 4, 2, 1, 0, 1, 2, 0, 4, 4, 2, 1, 0, 1, 4, 0, 0, 1, 3, 1, 2, 2, 3, 0, 4, 0, 0, 1]\n",
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#==================================valid\n",
    "print(valid_X.shape)\n",
    "print(valid_Y)\n",
    "gearing_valid_label = []\n",
    "for i in range(len(valid_Y)):\n",
    "    gearing_valid_label.append(np.argmax(valid_Y[i]))\n",
    "print(gearing_valid_label[:100])\n",
    "gearing_valid_classes = sorted(list(set(gearing_valid_label)))\n",
    "print(gearing_valid_classes)\n",
    "#==================================test\n",
    "print(test_X.shape)\n",
    "print(test_Y)\n",
    "gearing_test_label = []\n",
    "for i in range(len(test_X)):\n",
    "    gearing_test_label.append(np.argmax(test_Y[i]))\n",
    "print(gearing_test_label[:100])\n",
    "gearing_test_classes = sorted(list(set(gearing_test_label)))\n",
    "print(gearing_test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "siamese_net summary:\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 2048, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2048, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 100)          50772       input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 100)          0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100)          0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            101         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 50,873\n",
      "Trainable params: 50,873\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "siamese_net = models.load_siamese_net((window_size,1))\n",
    "print('\\nsiamese_net summary:')\n",
    "siamese_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sequential_3 is WDCNN:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 128, 16)           1040      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 64, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 64, 32)            1568      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 32, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 32, 64)            4160      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 16, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16, 64)            12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 8, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 6, 64)             12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 3, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               19300     \n",
      "=================================================================\n",
      "Total params: 50,772\n",
      "Trainable params: 50,772\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('\\nsequential_3 is WDCNN:')\n",
    "siamese_net.layers[2].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51782\n",
      "\n",
      "wdcnn_net summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 2048, 1)           0         \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 100)               50772     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 51,782\n",
      "Trainable params: 51,782\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "wdcnn_net = models.load_wdcnn_net()\n",
    "print('\\nwdcnn_net summary:')\n",
    "wdcnn_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import siamese\n",
    "# imp.reload(siamese)\n",
    "import utils\n",
    "imp.reload(utils)\n",
    "\n",
    "settings = {\n",
    "  \"N_way\": 10,           # how many classes for testing one-shot tasks>\n",
    "  \"batch_size\": 32,\n",
    "  \"best\": -1,\n",
    "  \"evaluate_every\": 600,   # interval for evaluating on one-shot tasks\n",
    "  \"loss_every\": 20,      # interval for printing loss (iterations)\n",
    "  \"n_iter\": 15000,\n",
    "  \"n_val\": 2,          #how many one-shot tasks to validate on?\n",
    "  \"n\": 0,\n",
    "  \"save_path\":\"\",\n",
    "  \"save_weights_file\": \"weights-best-10-oneshot-low-data.hdf5\"\n",
    "}\n",
    "\n",
    "\n",
    "exp_name = \"EXP-C\"\n",
    "#exps = [90,6600]\n",
    "exps = [90, 1000,  3000, 6600]\n",
    "#exps =[6600]\n",
    "see_rates = [0.7,0.8,0.9]\n",
    "times = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_training = True    # enable or disable train models. if enable training, save best models will be update.\n",
    "y_train_1 = []\n",
    "# for i in range(len(data.y_train)):\n",
    "def plot_confusion_matrix(cm, title,cmap):\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]    # 归一化\n",
    "        fig, ax = plt.subplots()\n",
    "        im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        ax.figure.colorbar(im, ax=ax)\n",
    "        # We want to show all ticks...\n",
    "        #ax.set(xticks=np.arange(cm.shape[1]),yticks=np.arange(cm.shape[0]),xticklabels=labels_name, yticklabels=labels_name)\n",
    "        ax.set(xticks=np.arange(cm.shape[1]),yticks=np.arange(cm.shape[0]))\n",
    "\n",
    "        # Rotate the tick labels and set their alignment.\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "                 rotation_mode=\"anchor\")\n",
    "\n",
    "        # Loop over data dimensions and create text annotations.\n",
    "        fmt = '.2f'\n",
    "        thresh = cm.max() / 2.\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                ax.text(j, i, format(cm[i, j], fmt),\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        fig.tight_layout()\n",
    "        return ax\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#train_classes = sorted(list(set(data.y_train)))\n",
    "train_classes = sorted(list(set(gearing_valid_label)))\n",
    "#train_indices = [np.where(data.y_train[:][:][0] == i)[0] for i in train_classes]\n",
    "train_indices = [np.where(gearing_valid_label[:][:][0] == i)[0] for i in train_classes]\n",
    "for exp in exps:\n",
    "    # enable the random seed for experimental reproduction\n",
    "    np.random.seed(exp)\n",
    "    scores_1_shot = []\n",
    "    scores_5_shot = []\n",
    "    num = int(exp/len(train_classes))\n",
    "    settings['evaluate_every'] = 300 if exp<1000 else 600\n",
    "    #print(settings['evaluate_every'])\n",
    "    for time_idx in range(times):\n",
    "#         np.random.seed(0)\n",
    "#         train_idxs = []\n",
    "#         val_idxs = []\n",
    "#         for i, c in enumerate(train_classes):\n",
    "#             select_idx = train_indices[i][np.random.choice(len(train_indices[i]), num, replace=False)]\n",
    "#             split = int(0.6*num)\n",
    "#             train_idxs.extend(select_idx[:split])\n",
    "#             end = num\n",
    "#             if(0.4*num>100):\n",
    "#                 end = split+100\n",
    "#             val_idxs.extend(select_idx[split:end])\n",
    "        #==========================================================\n",
    "        #X_train, y_train = data.X_train[:,:,0],data.y_train\n",
    "        #X_train, y_train = data.X_train[:exp,:,0],data.y_train[:exp]\n",
    "#         print(valid_X.shape)\n",
    "#         print(gearing_valid_label.shape)\n",
    "        X_train, y_train = valid_X[:exp,:],gearing_valid_label[:exp]\n",
    "        #===============================================================\n",
    "        #print(X_train.shape)\n",
    "        #print(\"=================X_train,y_train===================\")\n",
    "        X_train = X_train.reshape(len(X_train),2048,1)\n",
    "        #print(X_train.shape, y_train.shape)\n",
    "        #print(X_train, y_train)\n",
    "        X_val, y_val = test_X,gearing_test_classes\n",
    "        #print(\"=================X_val,y_val===================\")\n",
    "        #print(X_val, y_val)\n",
    "#         print(train_idxs[0:10])\n",
    "#         print(val_idxs[0:10])   \n",
    "            \n",
    "#         random_train_classes = [0]+list(np.random.choice(list(range(1,10)), 9, replace=False))\n",
    "    \n",
    "        print(\"\\n%s-%s\"%(exp,time_idx) + '*'*80)\n",
    "        settings[\"save_path\"] = \"tmp/%s/size_%s/time_%s/\" % (exp_name,exp,time_idx)\n",
    "        #print(settings[\"save_path\"])\n",
    "        data._mkdir(settings[\"save_path\"])\n",
    "        #random_select_classes = random_train_classes[:int(rate*len(train_classes))]\n",
    "        #print(random_select_classes)\n",
    "#         train_idxs_rate = np.array([np.where(y_train == i)[0] for i in train_classes]).reshape(-1)\n",
    "#         print(train_idxs_rate)\n",
    "#         val_idxs_rate =  np.array([np.where(y_val == i)[0] for i in gearing_test_classes]).reshape(-1)\n",
    "#         print(val_idxs_rate)\n",
    "#         X_train_rate, y_train_rate = X_train[train_idxs_rate],y_train[train_idxs_rate]\n",
    "#         print(X_train_rate, y_train_rate)\n",
    "#         print(\"===============================\")\n",
    "#         X_val_rate  = X_val[val_idxs_rate]\n",
    "#         print(val_idxs_rate)\n",
    "#         y_val_rate = y_val[val_idxs_rate]\n",
    "#         print(X_val_rate, y_val_rate)\n",
    "#         print(\"=================X_train_rate.shape=================\")\n",
    "#         print(X_train_rate.shape)\n",
    "#         print(y_train_rate)\n",
    "#         print(\"=================X_val_rate.shape=================\")\n",
    "#         print(X_val_rate.shape)\n",
    "#         print(y_val_rate)\n",
    "#         # load one-shot model and training\n",
    "        #print(X_train.shape)\n",
    "        test_X_train, test_y_train = data.X_train[:,:,0],data.y_train\n",
    "        print(len(test_X_train))\n",
    "        siamese_net = models.load_siamese_net()\n",
    "        siamese_loader = siamese.Siamese_Loader(X_train,\n",
    "                                        y_train,\n",
    "                                        test_X_train,\n",
    "                                        test_y_train)\n",
    "\n",
    "        if(is_training):\n",
    "            print(siamese.train_and_test_oneshot(settings,siamese_net,siamese_loader))\n",
    "\n",
    "        print(\"load best weights\",settings[\"save_path\"] + settings['save_weights_file'])\n",
    "        siamese_net.load_weights(settings[\"save_path\"] + settings['save_weights_file'])\n",
    "        \n",
    "        \n",
    "        siamese_loader = siamese.Siamese_Loader(valid_X,\n",
    "                                        gearing_valid_label,\n",
    "                                        test_X_train,\n",
    "                                        test_y_train)\n",
    "        s = 'val'\n",
    "        preds_5_shot = []\n",
    "        scores = []\n",
    "        for k in range(5):\n",
    "#             print(len(siamese_loader.classes[s]))\n",
    "#             print(len(siamese_loader.data[s]))\n",
    "            #val_acc,preds,c = siamese_loader.test_oneshot2(siamese_net,5,9003,verbose=False)\n",
    "            val_acc,preds,c = siamese_loader.test_oneshot2(siamese_net,len(siamese_loader.classes[s]),len(siamese_loader.data[s]),verbose=False)\n",
    "#             confusion_plot(preds[:,1],preds[:,0])\n",
    "#             print(preds[:,1])\n",
    "#             print(preds[:,1].shape)\n",
    "            \n",
    "#             print(data.y_train)\n",
    "#             print(data.y_train.shape)\n",
    "            C = confusion_matrix(preds[:,1],data.y_train)\n",
    "            #labels_name=[\"Normal\",\"Outter\",\"Inner\",\"Ball\"]\n",
    "            np.set_printoptions(precision=2)\n",
    "            plot_confusion_matrix(C,  \"HAR Confusion Matrix\",plt.cm.Blues)\n",
    "            plt.savefig('./Confusion_matrix_gearing2bearing/'+str(exp)+'_'+str(time_idx)+'_'+str(k)+'.png')\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            print(val_acc)\n",
    "            scores.append(val_acc)\n",
    "            preds_5_shot.append(preds[:,1])\n",
    "        preds = []\n",
    "        for line in np.array(preds_5_shot).T:\n",
    "            preds.append(np.argmax(np.bincount(line)))\n",
    "#         confusion_plot(np.array(preds),data.y_test) \n",
    "        #print(len(gearing_test_label))\n",
    "        #print(len(np.array(preds)))\n",
    "        score_5_shot = accuracy_score(test_y_train,np.array(preds))*100\n",
    "        print('==============================plot_confusion_matrix_score_5_shot=========================================')\n",
    "        C = confusion_matrix(np.array(preds),test_y_train)\n",
    "        #labels_name=[\"Normal\",\"Outter\",\"Inner\",\"Ball\"]\n",
    "        np.set_printoptions(precision=2)\n",
    "        plot_confusion_matrix(C,  \"HAR Confusion Matrix\",plt.cm.Blues)\n",
    "        plt.savefig('./Confusion_matrix_gearing2bearing/score_5_shot_'+str(exp)+'_'+str(time_idx)+'_'+str(k)+'.png')\n",
    "        plt.show()\n",
    "        print('5_shot:',score_5_shot)\n",
    "        scores_1_shot.append(scores[0])\n",
    "        scores_5_shot.append(score_5_shot)\n",
    "    print(scores_1_shot)\n",
    "    print(scores_5_shot)\n",
    "    #a =pd.DataFrame(np.array(scores_1_shot).reshape(-1,len(see_rates)))\n",
    "    a =pd.DataFrame(np.array(scores_1_shot))\n",
    "    a.columns = [\"gearing,9003\"]\n",
    "    a.to_csv(\"tmp/%s/size_%s/scores_1_shot.csv\" % (exp_name,exp),index=True)\n",
    "\n",
    "\n",
    "    #a =pd.DataFrame(np.array(scores_5_shot).reshape(-1,len(see_rates)))\n",
    "    a =pd.DataFrame(np.array(scores_5_shot))\n",
    "    a.columns = [\"gearing,9003\"]\n",
    "    a.to_csv(\"tmp/%s/size_%s/scores_5_shot.csv\" % (exp_name,exp),index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [90, 6600]\n",
    "#exps = [90,500,1000,2000,3000,6600]\n",
    "scores_1_shot_all = pd.DataFrame()\n",
    "scores_5_shot_all = pd.DataFrame()\n",
    "\n",
    "for exp in exps:\n",
    "    file_path = \"tmp/%s/size_%s\" % (exp_name,exp)\n",
    "    print(file_path)\n",
    "    tmp_data = pd.read_csv(\"%s/scores_1_shot.csv\" % (file_path), \n",
    "                           sep=',', index_col=0)\n",
    "    print(tmp_data)\n",
    "    #tmp_data = pd.DataFrame(tmp_data.values.reshape(-1,len(see_rates)))\n",
    "#     tmp_data = pd.DataFrame(tmp_data.values.reshape(-1,50))\n",
    "#     tmp_data.columns = [len(gearing_valid_label)]\n",
    "#     tmp_data['model'] = 'One-shot'\n",
    "#     tmp_data['exp'] = exp \n",
    "#     scores_1_shot_all = pd.concat([scores_1_shot_all,tmp_data],axis=0)\n",
    "\n",
    "    tmp_data = pd.read_csv(\"%s/scores_5_shot.csv\" % (file_path), \n",
    "                           sep=',', index_col=0)\n",
    "    print(tmp_data)\n",
    "    #tmp_data = pd.DataFrame(tmp_data.values.reshape(-1,len(see_rates)))\n",
    "#     tmp_data = pd.DataFrame(tmp_data.values.reshape(-1,50))\n",
    "#     tmp_data.columns = [len(gearing_valid_label)]\n",
    "#     tmp_data['model'] = 'Five-shot'\n",
    "#     tmp_data['exp'] = exp \n",
    "#     scores_5_shot_all = pd.concat([scores_5_shot_all,tmp_data],axis=0)\n",
    "\n",
    "\n",
    "scores_1_shot_all.to_csv(\"tmp/%s/scores_1_shot_all.csv\" % (exp_name), float_format='%.6f', index=True)\n",
    "scores_5_shot_all.to_csv(\"tmp/%s/scores_5_shot_all.csv\" % (exp_name), float_format='%.6f', index=True)\n",
    "\n",
    "scores_1_shot_all['model'] = 'One-shot'\n",
    "scores_5_shot_all['model'] = 'Five-shot'\n",
    "\n",
    "scores_all = pd.concat([scores_1_shot_all,scores_5_shot_all],axis=0)\n",
    "scores_all.to_csv(\"tmp/%s/scores_all.csv\" % (exp_name), float_format='%.6f', index=True)   \n",
    "\n",
    "scores_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
